{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c7f8801-69a1-4398-8827-05f922572358",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **Phase 3: Experimentation, Fine-Tuning, and Final Report**\n",
    "\n",
    "==========================================================================================================================================================\n",
    "\n",
    "# Abstract\n",
    "\n",
    "In this project, we tackled the challenging problem of predicting flight delay severity using the OTPW dataset, a compilation of flight performance and weather data. Our objective was to develop a robust, scalable machine learning pipeline capable of delivering accurate predictions while addressing common pitfalls such as data leakage and overfitting. In the initial phases, we established a solid base with multinomial logistic regression, setting the foundation for more advanced methodologies. Subsequent phases focused on the implementation and evaluation of sophisticated models, including ElasticNet Logistic Regression, Gradient Boosted Decision Trees (GBDT), and Multilayer Perceptron (MLP) neural networks, with the latter being a key focus of this phase.\n",
    "\n",
    "For the MLP architecture, we explored multiple configurations, including single-hidden-layer and two-hidden-layer networks, designed to capture complex nonlinear relationships in the data. Leveraging custom-built functions, we implemented a distributed training mechanism using PySpark to ensure scalability across CPU-based clusters. To enhance the model's robustness, early stopping strategies were employed, guided by validation set performance metrics. These strategies not only mitigated overfitting but also facilitated hyperparameter tuning, such as learning rate decay and batch size optimization. Moreover, feature engineering played a pivotal role, with the integration of time-based features. These enhancements allowed us to capture intricate temporal and spatial dependencies within the dataset.\n",
    "\n",
    "Our experiments demonstrated significant improvements over the baseline, with the MLP model achieving a test accuracy of 0.8993 in predicting flight delay severity across five classes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45ddbb77-bcc9-4b91-be08-8ec1be7092aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Team Members\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Name</th>\n",
    "        <th>Email</th>\n",
    "        <th>Photos</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Achyuth Kolluru</td>\n",
    "        <td>akolluru@berkeley.edu</td>\n",
    "        <td> <img src=\"https://raw.githubusercontent.com/AchyuthKoll/w261_images/master/Achyuth.jpg\" width=\"150\"> </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Bernardo Cobos</td>\n",
    "        <td>bernardoc@berkeley.edu</td>\n",
    "        <td> <img src=\"https://raw.githubusercontent.com/AchyuthKoll/w261_images/master/Bernardo.png\" width=\"150\"> </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Hitesh Basantani</td>\n",
    "        <td>hitesh.basantani@berkeley.edu</td>\n",
    "        <td> <img src=\"https://raw.githubusercontent.com/AchyuthKoll/w261_images/master/Hitesh.jpg\" width=\"150\"> </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Omar Jamil</td>\n",
    "        <td>ojamil@berkeley.edu</td>\n",
    "        <td> <img src=\"https://raw.githubusercontent.com/AchyuthKoll/w261_images/master/Omar.png\" width=\"150\"> </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Mohammad Hafezi</td>\n",
    "        <td>hafezi@berkeley.edu</td>\n",
    "        <td> <img src=\"https://raw.githubusercontent.com/AchyuthKoll/w261_images/master/Mohammad.jpg\" width=\"150\"> </td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dbcc3bb7-3d7f-4d4f-b8c8-46620575d34b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Credit Assignment Plan\n",
    "<table border=\"1\" cellpadding=\"4\" cellspacing=\"0\">\n",
    "    <tr>\n",
    "        <th>Phase</th>\n",
    "        <th>Description & SMART Goal</th>\n",
    "        <th>Assigned Member</th>\n",
    "        <th>Status</th>\n",
    "        <th>Estimated Person-Hours</th>\n",
    "    </tr>\n",
    "    <!-- FP Phase 1 -->\n",
    "    <tr>\n",
    "        <td rowspan=\"3\">FP Phase 1: Project Plan</td>\n",
    "        <td>Clarify objectives, datasets, and project scope. SMART Goal: Complete project summary by Nov. 4.</td>\n",
    "        <td>All Members</td>\n",
    "        <td>Completed</td>\n",
    "        <td>27</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Dataset Overview</td>\n",
    "        <td>Describe datasets, joins, tasks, and metrics. SMART Goal: Document data structure by Nov. 4.</td>\n",
    "        <td>All Members</td>\n",
    "        <td>Completed</td>\n",
    "        <td>15</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Initial EDA</td>\n",
    "        <td>Conduct initial EDA to identify trends and outliers. SMART Goal: Summarize key findings by Nov. 4.</td>\n",
    "        <td>All Members</td>\n",
    "        <td>Completed</td>\n",
    "        <td>12</td>\n",
    "    </tr>\n",
    "    <!-- FP Phase 2 -->\n",
    "    <tr>\n",
    "        <td rowspan=\"4\">FP Phase 2: EDA & Baseline Pipeline</td>\n",
    "        <td>Handle missing or inconsistent data. SMART Goal: Complete data cleaning by Nov. 10.</td>\n",
    "        <td>Hitesh, Omar</td>\n",
    "        <td>Completed</td>\n",
    "        <td>60</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Detailed EDA</td>\n",
    "        <td>Analyze dataset distributions and correlations in depth. SMART Goal: Complete by Nov. 10.</td>\n",
    "        <td>Achyuth, Hitesh, Bernardo</td>\n",
    "        <td>Completed</td>\n",
    "        <td>18</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Baseline Model</td>\n",
    "        <td>Develop baseline pipeline for model benchmarking. SMART Goal: Build baseline model by Nov. 12.</td>\n",
    "        <td>Bernardo, Mohammad, Omar</td>\n",
    "        <td>Completed</td>\n",
    "        <td>12</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Scalability and Efficiency</td>\n",
    "        <td>Implement distributed/parallel training and scoring. SMART Goal: Complete scalable model by Nov. 20.</td>\n",
    "        <td>Bernardo, Achyuth, Mohammad</td>\n",
    "        <td>Completed</td>\n",
    "        <td>12</td>\n",
    "    </tr>\n",
    "    <!-- FP Phase 3 -->\n",
    "    <tr>\n",
    "        <td rowspan=\"3\">FP Phase 3: Algorithm Selection & Final Report</td>\n",
    "        <td>Compare model performances and select the optimal one. SMART Goal: Finalize model by Dec. 5.</td>\n",
    "        <td>Bernardo, Omar, Achyuth</td>\n",
    "        <td>Completed</td>\n",
    "        <td>24</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Model Fine-Tuning</td>\n",
    "        <td>Optimize hyperparameters and finalize model. SMART Goal: Achieve target metrics by Dec. 10.</td>\n",
    "        <td>Hitesh, Achyuth</td>\n",
    "        <td>Completed</td>\n",
    "        <td>12</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Final Report</td>\n",
    "        <td>Prepare and submit the final report. SMART Goal: Submit by Dec. 14.</td>\n",
    "        <td>Omar, Mohammad</td>\n",
    "        <td>Completed</td>\n",
    "        <td>24</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3659bb4-4f8f-4ba7-8b7e-ded54b2e6722",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Introduction & Project Description \n",
    "\n",
    "We set out to predict flight delay severity, defined initially by the `DEP_DELAY_GROUP` variable, to assist airlines, airports, and travelers in anticipating and mitigating disruptions. Delay severity classification enables effective resource allocation, schedule adjustments, and contingency planning. Our earlier phases classified flight severity using a multinomial logistic regression model, which, while interpretable, did not fully leverage the complexity of our integrated flight-weather dataset.\n",
    "\n",
    "In this phase, our focus shifted toward experimenting with more sophisticated models and feature sets. By leveraging advanced machine learning techniques, such as ElasticNet logistic regression, GBDTs, and MLP neural networks, we aimed to capture non-linear relationships and complex temporal or network patterns. We introduced time-based features to reflect recency and seasonality of delays. Our final goal was to achieve improved predictive performance on both the validation sets and an unseen year-2019 test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b74f9cb1-77a6-4f87-b5c0-6e0d6ba947fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Data Description & Feature Engineering \n",
    "\n",
    "We used the 5-year OTPW dataset, which integrates flight data from the U.S. Department of Transportation with weather data from the National Oceanic and Atmospheric Administration for the years 2015 - 2019. Training was done on 2015-2018 data, while 2019 was held out as a test set. The dataset includes detailed records of flight schedules, delays, cancellations, and extensive hourly weather observations aligned to the departure origin airports. \n",
    "\n",
    "## Data Lineage & Transformations:  \n",
    "Missing values were imputed using group-based averages, and we introduced indicator columns to track imputation. We then standardized data formats and ensured time alignment to prevent data leakage from future periods.To handle the grouping of delays, quantie-based bucketing was applied to the ['Departure Delay'] variable. Specifically delays were grouped into four buckets using the 50th (Q2) percentile and 75th (Q3) percentile of the data distribution as thresholds. The defined buckets were:\n",
    "\n",
    "- **Bucket 0**: Flights with no delay (`Dep_Delay = 0`).\n",
    "- **Bucket 1**: Small delays (`15 minutes ≤ Dep_Delay < 30 minutes`).\n",
    "- **Bucket 2**: Moderate delays (`30 minutes ≤ Dep_Delay < 45 minutes`).\n",
    "- **Bucket 3**: Significant delays (`Dep_Delay ≥ 45 minutes`).\n",
    "- **Bucket 4**: Flights that were canceled (`Dep_Delay = 13`).\n",
    "\n",
    "The reduction in number of buckets for our target variable was to deal with overly sparse distribution of the original values. \n",
    "\n",
    "## Feature Families:  \n",
    "- Temporal Features: [e.g., `DAY_OF_WEEK` , `MONTH, DEP_TIME_BLK`] capture daily/weekly patterns.  \n",
    "- Flight Characteristics: [e.g., `OP_UNIQUE_CARRIER`, `TAIL_NUM`, `CRS_ELAPSED_TIME`] encode airline/operator identity and flight-level attributes.  \n",
    "- Weather Features: [e.g., `HourlyDryBulbTemperature`, `HourlyVisibility`, `HourlyPrecipitation`] provide environmental context.  \n",
    "- Time-based Feature (New in Phase 3): Seasonality.  \n",
    "\n",
    "## EDA of New Features:\n",
    "\n",
    "For the EDA we included ~ 16 numerical variables containing hourly Weather data, cloud/sky information, day of week, month of year, etc. \n",
    "\n",
    "In this work, we are trying to predict flight delays bucketed in to 5 groups. These groups will be based on the variable `DEP_DELAY`. Data below consists of all 5 years of data sampled to 5% for the sake of plotting. We see that majority of the flights are on time or have relatively small departure delay. We also notice a large tail to the right extending all the way out to 2000 minute delay which is a nearly 33 hour delay. While this looks to be an outlier, we decided to keep this included as this delay is possible for some routes which run on a much lower frequency. \n",
    "\n",
    "\n",
    "<img src=\"https://github.com/basantani-hitesh/w261/blob/main/departure_delay_5y.png?raw=true\">\n",
    "\n",
    "We also reviewed the distribution of the hourly weather information, such as HourlyPrecipitaion, Wind gusts, pressure changes. Some of these are highlighted below. These variables directly end up as inputs in to our model.\n",
    "\n",
    "### Hourly Station Pressure \n",
    "\n",
    "The hourly station pressure data is in the range of 20 inHg to 31 inHg. This data is multi-modal. Coupled with the average pressure for a given airport, we thought this variable might provide predictive power in flight delays as it might be indicative of an upcoming storm.\n",
    "\n",
    "<img src=\"https://github.com/basantani-hitesh/w261/blob/main/HourlyStationPressure.png?raw=true\">\n",
    "\n",
    "### Hourly Dry Bulb Teperature\n",
    "\n",
    "The hourly dry bulb temperature has a range from -25F to 120 F showcasing the temperature ranges experienced by all the airports in the United states over the course of 5 years. The distribution has a mode of around 65-70F with left skew towards the lower temperatures. The outliers below 0F and above 105F might be of interest in the predictability.\n",
    "\n",
    "<img src=\"https://github.com/basantani-hitesh/w261/blob/main/hourlydrybulbtemperature.png?raw=true\">\n",
    "\n",
    "## Derived Features  \n",
    "\n",
    "### Sky Conditions  \n",
    "\n",
    "`Coverage1`, `Coverage2`, `Coverage3` (sky coverage layers), along with their corresponding `LayerAmount` and `CloudBaseHeight`, provide granular weather details derived from the `HourlySkyConditions` column. These features were parsed to enable more detailed weather analysis relevant to flight performance and delay predictions.\n",
    "\n",
    "The `HourlySkyConditions` column represents multiple layers of sky coverage for a given timestamp. Each layer contains:  \n",
    "- **Sky Coverage**: Codes like `CLR` (Clear), `BKN` (Broken), `OVC` (Overcast), which describe the extent of cloud coverage.  \n",
    "- **Layer Amount**: A numerical value representing cloud density.  \n",
    "- **Cloud Base Height**: The altitude of the cloud layer's base, measured in hundreds of feet.\n",
    "\n",
    "An example of the original format:  \n",
    "`\"BKN:07 250 BKN:07 100 OVC:08 180\"`  \n",
    "This describes three layers:  \n",
    "1. Broken clouds with density `07` at a base height of `250` (hundreds of feet).  \n",
    "2. Broken clouds with density `07` at a base height of `100`.  \n",
    "3. Overcast clouds with density `08` at a base height of `180`.\n",
    "\n",
    "#### Parsing Process  \n",
    "1. **Regular Expression Extraction**:  \n",
    "   - A regular expression was used to parse the `HourlySkyConditions` string, splitting it into distinct components:\n",
    "     - `Coverage`: Extracts the sky coverage codes (e.g., `BKN`, `OVC`).\n",
    "     - `LayerAmount`: Extracts the corresponding numerical density values.\n",
    "     - `CloudBaseHeight`: Extracts the altitude values.\n",
    "\n",
    "2. **Column Derivation**:  \n",
    "   - Up to three separate columns (`Coverage1`, `Coverage2`, `Coverage3`) were created to represent the sequential layers of coverage in the string.\n",
    "   - Similarly, three columns for `LayerAmount` and three for `CloudBaseHeight` were derived, corresponding to each coverage layer.\n",
    "\n",
    "3. **Handling Missing Layers**:  \n",
    "   - If the original string contained fewer than three layers, the missing `Coverage` values were set to `CLR` (Clear).\n",
    "   - Missing `LayerAmount` and `CloudBaseHeight` values were set to `0` to maintain consistency.\n",
    "\n",
    "#### Example Transformation  \n",
    "**Original Input**: `\"BKN:07 250 BKN:07 100 OVC:08 180\"`  \n",
    "**Resulting Columns**:  \n",
    "- `Coverage1`: `BKN`, `Coverage2`: `BKN`, `Coverage3`: `OVC`  \n",
    "- `LayerAmount1`: `07`, `LayerAmount2`: `07`, `LayerAmount3`: `08`  \n",
    "- `CloudBaseHeight1`: `250`, `CloudBaseHeight2`: `100`, `CloudBaseHeight3`: `180`\n",
    "\n",
    "This transformation enabled more granular analysis of cloud coverage patterns, aligning weather data with flight conditions more effectively.\n",
    "\n",
    "### Imputation Indicators  \n",
    "\n",
    "Binary indicator columns were introduced across all imputed columns to track where missing values were replaced. These indicators are critical for downstream analysis, as they retain the original missingness information for potential pattern identification.  \n",
    "\n",
    "#### Implementation:  \n",
    "- **MissingValueIndicators**:  \n",
    "   For delay-related columns like `DEP_DELAY` and `DEP_DELAY_GROUP`, for example, indicators such as `DEP_DELAY_missing` and `DEP_DELAY_GROUP_missing` were created. These flags help identify rows where delay data was unavailable. The same approach was applied across the boards to columns where missing values were being imputed.\n",
    "\n",
    "These indicators ensure that the imputation process is transparent, providing flexibility for modeling and exploratory analyses.\n",
    "\n",
    "### Feature Transformations  \n",
    "\n",
    "- **Categorical Encoding**:  \n",
    "  Label encoding was applied to columns such as `DEP_TIME_BLK`, `CANCELLATION_CODE`, and `OP_UNIQUE_CARRIER` using PySpark’s `StringIndexer`. This transformed categorical variables into numerical indices for compatibility with machine learning models. For each column where label encoding was applied, a new column as introduced with the corresponding indexed values (for example, 'CANCELLATION_CODE_index')\n",
    "\n",
    "- **One Hot Encoding**:\n",
    "  For Pyspark ML's multinomial logistic regression function, categorical variables also needed to be one-hot encoded. This was done using a OneHotEncoder for the categorically-encoded variables.\n",
    "\n",
    "- **Further Imputation**\n",
    "  Many hourly weather readings, such as `HourlyPrecipitation` and `HourlyVisibility`, still had missing values. All of these were datatype `double`, so in the ML pipeline, these were imputed via an Imputer class, with a \"mean\" imputation strategy. \n",
    "\n",
    "- **Vectorization**\n",
    "  Finally, Pyspark's logistic regression requires all features to be in a single vector, while the categorical predicted label can be in its own non one-hot encoded column. These transformed features were all brought together using a VectorAssembler object.\n",
    "\n",
    "### Seasonality in Departure Delay\n",
    "\n",
    "In this section we will discuss our efforts in extracting the seasonality trends in the departure delay and cancellations to try and extract information that may give predictive power to our model build. \n",
    "\n",
    "#### Average Delay by Carrier\n",
    "\n",
    "To get a feel what the recent airline delay looks like, we computed a new column called the average_departure_delay. This column contains the average delay experienced by the airline grouped by the hour and day of the week. In hindsight, average departure delay by each airport might provide more predictive power than grouping by airline, but as we see in the results, there is some predictve power in the metric we have computed here as well. Below heat map shows the delay for a couple of airlines, a comprehensive list is available in the appendix 1. \n",
    "\n",
    "Below graphs show the heat maps made from this data for Delta and US airlines. This average delay from teh data set is saved for each for each entry in the data table for use by our model\n",
    "\n",
    "<img src=\"https://github.com/basantani-hitesh/w261/blob/main/departure_delay_delta.png?raw=true\">\n",
    "\n",
    "<img src=\"https://github.com/basantani-hitesh/w261/blob/main/departure_delay_us.png?raw=true\">\n",
    "\n",
    "#### Seasonality in Flight Cancellation by Airline\n",
    "\n",
    "One feature we thought that would add predictive power to our model is the average departure delay of flights for each airline by day of the week and by month of the year. For this feature creation, we grouped the average delay by the airline for each departure day. Then we ran the seasonality analysis using seasonal decomposition in pyspark, running the seasonal decomposition to determine trends over a 7 day recurring period and another analysis by a 30 day repeating period to get the weekly and monthly seasonality summary. These features then got saved in to a new column called weekly and monthly seasonality. \n",
    "\n",
    "These graphs illustrate the seasonality component by week. We The seasonality component is calculated using the formula:\n",
    "\n",
    "<br>\n",
    "\n",
    "                                                            Seasonality Component = Data − (Trend + Residual)\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "This is derived by fitting a seasonal model that minimizes the residuals to extract the repeating weekly and monthly delay patterns. The monthly patterns of delay are shown below:\n",
    "<br>\n",
    "\n",
    "<img src=\"https://github.com/basantani-hitesh/w261/blob/main/monthly_seasonality.png?raw=true\">\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2a21ce3-2913-4144-9053-845eb87868a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Leakage Analysis\n",
    "\n",
    "A leakage analysis was conducted to address all potential cardinal sins of leakage, ensuring the integrity of the model's evaluation and performance in deployment scenarios.\n",
    "\n",
    "### Temporal Leakage\n",
    "The dataset was split temporally, with the last year (2019) reserved for testing and the preceding four years (2015–2018) used for training and validation. This approach ensures that no future information influences the training process, maintaining realistic evaluation metrics.\n",
    "\n",
    "### Target Leakage\n",
    "While efforts were made to prevent target leakage, there is some risk associated with features like `avg_delay` and the seasonality columns (`weekly_seasonal_component`, `monthly_seasonal_component`). These features were created by grouping data based on factors such as departure airport, airline, and time of the week or month. However, these groupings were not strictly confined to past data, meaning they may inadvertently include information from the current or future periods, posing a potential leakage risk.\n",
    "\n",
    "### Data Split Leakage\n",
    "No data split leakage exists, as training, validation, and test datasets were separated based on date, with no overlap. However, as mentioned above some of the features may be subject to leakage due to the nature of how they were calculated.\n",
    "\n",
    "### Preprocessing Leakage\n",
    "Preprocessing steps, such as imputing missing values, were applied to the entire dataset rather than separately for the training and test sets. For instance, mean-based imputations for weather features and time series data used statistics computed across both training and test data. While this is not a classical example of leakage, it does mean that imputations may incorporate information from the test set, potentially influencing model training.\n",
    "\n",
    "### Proxy Variables\n",
    "Proxy variables that could inadvertently reveal target information were identified and removed during training. This includes variables that directly or indirectly contained information about delays or cancellations, which were excluded to maintain the model's predictive integrity.\n",
    "\n",
    "### Model or Pipeline Overfitting\n",
    "There is a suspicion of model or pipeline overfitting. The MLP model predominantly predicted only Classes 0 and 1, effectively acting as a binary classifier. This behavior suggests the model struggled to generalize across all delay categories, indicating inefficiency or potential overfitting within the pipeline. More time should be invested in evaluating whether the observed behavior stems from model overfitting during cross-validation folds. This could be caused by factors such as an imbalance in the class distribution across folds, insufficient regularization, or improperly isolatied preprocessing steps. Since some preprocessing steps were computed using data from multiple folds, this could indavetently leak information between training and test sets. \n",
    "\n",
    "### Label Contamination\n",
    "While no feature engineering was directly based on the target variable, features like `avg_delay`, `weekly_seasonal_component`, and `monthly_seasonal_component` may have introduced indirect leakage: These features are derived from group-level aggregations and seasonality trends, which could inadvertently include future or current data points when applied to the test set. This potential source of leakage was unfortunately discovered after modeling was performed, but is being noted here for completeness.\n",
    "\n",
    "### Summary\n",
    "Despite efforts to minimize leakage, some potential risks remain, particularly concerning features like `avg_delay` and the seasonality components. These aspects should be addressed in future iterations by recalculating features strictly from past data and isolating preprocessing to the training dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93baeb2c-9777-465c-a52e-8606e2c57cc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Modeling Pipelines & Experiments\n",
    "\n",
    "Our modeling pipelines consist of sequential steps:\n",
    "\n",
    "1. **Preprocessing & Encoding**:  \n",
    "   Input data → Imputation of missing weather values → One-hot encoding of categorical variables + Cardinality reduction of target variable 'Departure Delay Group' into 5 buckets → Assembling into a feature vector.\n",
    "\n",
    "2. **Dimensionality & Feature Enhancement**:  \n",
    "   Introduction of time-based features were integrated after initial cleaning and before final vector assembly.\n",
    "\n",
    "3. **Model Training**:  \n",
    "   Models tested include multi-class elasticNet Logistic Regression, Gradient-Boosted Trees (binary by default but adapted via re-labeling), and MLP (supports multi-class). We set aside validation sets by splitting the training data for time-series cross-validaton. This heped us to to tune hyperparameters. We also implemented early stopping.\n",
    "\n",
    "**Hyperparameters & Settings**:  \n",
    "   - Gradient-Boosted Trees: Tuned `num_rounds`, `eta`, and `max_depth`  \n",
    "   - MLP: Tuned `maxIter`, `blockSize`, and experimented with different network layer configurations.\n",
    "   - ElasticNet Logistic Regression: Tuned `regParam` and `elasticNetParam`\n",
    "\n",
    "**Loss Functions**:  \n",
    "   - MLP uses categorical cross-entropy loss for multi-class classification.\n",
    "$$\n",
    "L = -\\sum_{i=1}^N y_i \\log(\\hat{y}_i)\n",
    "$$\n",
    "   - The Logistic Regression model used ElasticNet Loss/regularization.\n",
    "   $$\n",
    "L_{reg} = L + \\alpha \\lambda \\sum_{j=1}^M |w_j| + (1 - \\alpha) \\lambda \\sum_{j=1}^M w_j^2\n",
    "$$\n",
    "   - Gradient-Boosted Trees use impurity measures (like Gini) internally.\n",
    "\n",
    "## Cluster & Runtime:  \n",
    "**Cluster Configuration**: \n",
    "\n",
    "- Runtime: \n",
    "  - DBR 16.0 ML | Spark 3.5.0 | Scala 2.12\n",
    "\n",
    "- Driver: \n",
    "  - Standard_Ds5_v2 | 56 GB | 16 Cores\n",
    "\n",
    "- Workers: \n",
    "  - Standard_DS3_v2 | 84 GB | 24 Cores\n",
    "    - 6-10 workers were used\n",
    "\n",
    "## Experiments:\n",
    "\n",
    "We evaluated multiple models, starting with a baseline classifier and progressing through logistic regression, XGBoost, and a Multilayer Perceptron (MLP). Each model's performance is assessed on the temporally split dataset.\n",
    "\n",
    "### 1. Baseline Classifier\n",
    "\n",
    "A dummy classifier (always guessing \"NO DELAY\") was used to set baseline metrics. Those are as follow: \n",
    "\n",
    "- Weighted Precision: 0.6517\n",
    "\n",
    "- Weighted Recall: 0.8073\n",
    "\n",
    "- Weighted F1-Score: 0.7212\n",
    "\n",
    "### 2. Logistic Regression\n",
    "\n",
    "The Phase 1 and 2 logistic regression models were updated to now account for ElasticNet. ElasticNet loss is similar to categorical cross-entropy loss, except it introduces penalties for the model weights  \\\\(w_i\\\\).\n",
    "\n",
    "ElasticNet Regularization Loss:\n",
    "$$\n",
    "L_{reg} = L + \\alpha \\lambda \\sum_{j=1}^M |w_j| + (1 - \\alpha) \\lambda \\sum_{j=1}^M w_j^2\n",
    "$$\n",
    "\n",
    "This meant that we needed to choose two hyperparameters in Phase 3: \n",
    "\n",
    "- Regularization parameter \\\\( \\lambda \\\\)\n",
    "- ElasticNet \"mixing\" parameter \\\\( \\alpha \\\\)\n",
    "\n",
    "Time series cross-validation grid search was performed to choose these hyperparamaters. The hyperparameters we tried were: \n",
    "\n",
    "- \\\\( \\lambda \\\\): **0.01**, 0.1\n",
    "- \\\\( \\alpha \\\\): 0.0, 0.5, **1.0**\n",
    "\n",
    "On the 5-year dataset, the best hyperparameters were those highlighted above. \n",
    "\n",
    "#### Results\n",
    "The test results on the 5y data (ie, evaluated on the data for the year 2019) are as follow:\n",
    "\n",
    "- Weighted Precision: 0.6788\n",
    "\n",
    "- Weighted Recall: 0.8095\n",
    "\n",
    "- Weighted F1-Score: 0.7259\n",
    "\n",
    "### 3. XGBoost\n",
    "\n",
    "For the XGBoost model, we used a grid search to arrive at the following model parameters: num_round=50, max_depth=4, eta=0.3, num_workers=4, max_bin=256, tree_method=\"approx\". During the grid search, we searched the following hyperparameters to arrive at the final values: The num_rounds [50, 100, 2], eta = [0.2, 0.3, 2], max_depth = [2, 4, 1].  \n",
    "\n",
    "Due to memory constraints, we only trained on 10% of the full data on this algorithm. The test_data was evaluated on the full dataset. The results are shown below.\n",
    "\n",
    "We see a weighted accuracy of ~ 68% with model being most accurate for class no delay and a delay of 30-45 minutes (class 2). The prediction for class 1, 3, and 4 is very poor < 25%.A full matrix of performance for each class is shown in the table below \n",
    "\n",
    "<img src=\"https://github.com/basantani-hitesh/w261/blob/main/xgboost_results.png?raw=true\" alt=\"Image\">\n",
    "\n",
    "We used the get feature importance parameter to get a breakdown of which features were important according to our model. The results are shown below where the hour_of_day was the most important predictor for this algorithm. This jives well with the seasonality delay we saw during feature engineering where the delay is significant for certain parts of the day vs. others for each airline.  \n",
    "\n",
    "<img src=\"https://github.com/basantani-hitesh/w261/blob/main/get_booster.png?raw=true\">\n",
    "\n",
    "Other strong predictors were the average delay, this showed that the average departure delay feature described above in the engineering section. We also had temperature, visibility, and precipitation and pressure as contributors to the model from the weather features. \n",
    "\n",
    "The tail number or the particular route of a given flight along with the cloud information, one hot encoded made it as the top 10 parameters during training.\n",
    "\n",
    "### 4. Multi-Layer Percepton (Neural Network)\n",
    "\n",
    "For the MLP model in Phase 3, we conducted hyperparameter tuning using grid search with cross-validation to determine the optimal configuration for network architecture and training settings. This process aimed to maximize performance on the validation set while ensuring generalization to the test set.\n",
    "\n",
    "#### Hyperparameter Tuning Details\n",
    "\n",
    "- **Search Strategy**: Grid search with cross-validation.\n",
    "- **Parameters Explored**:\n",
    "  - **Network Architecture**: Variations in the number of layers and units per layer.\n",
    "  - **Training Configuration**: Maximum iterations and block size for batch processing.\n",
    "\n",
    "#### Best Parameters Identified\n",
    "\n",
    "The optimal configuration identified during the grid search was as follows:\n",
    "\n",
    "- **Network Architecture**: 4 layers including two hidden layers and input/output layers: `[36, 30, 15, 5]`.\n",
    "- **Max Iterations**: 250.\n",
    "- **Block Size**: 128.\n",
    "\n",
    "This configuration provided the best balance between accuracy and training efficiency.\n",
    "\n",
    "#### Results\n",
    "\n",
    "The Multilayer Perceptron (MLP) model demonstrated strong performance on the test dataset, with the following key metrics:\n",
    "\n",
    "- **Weighted Precision**: 0.8435  \n",
    "- **Accuracy**: 0.8993  \n",
    "- **Weighted F1-Score**: 0.8650  \n",
    "\n",
    "#### Class-Level Performance\n",
    "\n",
    "The detailed class-level metrics are as follows:\n",
    "\n",
    "| Class   | Precision | Recall   | F1-Score |\n",
    "|---------|-----------|----------|----------|\n",
    "| Class 0 | 0.979711  | 0.994790 | 0.987193 |\n",
    "| Class 1 | 0.533457  | 0.975482 | 0.689727 |\n",
    "| Class 2 | 0.000000  | 0.000000 | 0.000000 |\n",
    "| Class 3 | 0.000000  | 0.000000 | 0.000000 |\n",
    "| Class 4 | 0.000000  | 0.000000 | 0.000000 |\n",
    "\n",
    "#### Observations\n",
    "\n",
    "1. **High Performance for \"No Delay\"**:  \n",
    "   The model performed exceptionally well for **Class 0 (\"No Delay\")**, achieving an F1-score of 0.9872 with near-perfect precision and recall. This indicates the model's strong ability to identify flights without delays.\n",
    "\n",
    "2. **Moderate Performance for \"Small Delays\"**:  \n",
    "   For **Class 1 (\"Small Delays\")**, the model achieved a respectable F1-score of 0.6897, with high recall (0.9755) but relatively low precision (0.5335). This suggests the model tends to over-predict small delays.\n",
    "\n",
    "3. **Poor Performance for Other Classes**:  \n",
    "   The model failed to predict Classes 2, 3, and 4 (moderate delays, significant delays, and cancellations). The F1-scores for these classes are 0.0000, indicating no true positives were predicted for these categories.\n",
    "\n",
    "## Experiment Summary Table:\n",
    "\n",
    "| Exp ID | Model                         | Best Hyperparameters                       | Validation Recall | Train Time (min) | Notes                                   |\n",
    "|--------|-------------------------------|-------------------------------------------|-------------------|------------------|------------------------------------------|\n",
    "| 0      | Dummy Classifier              | N/A                                       | 0.8073            | N/A              | Baseline for comparison                   |\n",
    "| 1      | ElasticNet Logistic Regression | `regParam` = 0.01 and `elasticNetParam` = 1.0 | 0.8060            | 14 Minutes       |                                          |\n",
    "| 2      | Gradient-Boosted Trees        | `num_round` = 50, `max_depth` = 4, `eta` = 0.3, `num_workers` = 4, `max_bin` = 256, `tree_method` = \"approx\" | 0.6800            | 19 Minutes      | Trained on 10% of the data due to memory constraints. Best performance for \"No Delay\" and \"30-45 minutes\" delay categories. Poor performance on Classes 1, 3, and 4. |\n",
    "| 3      | MLP                           | `Network Architecture`: [36, 30, 15, 5], `Max Iterations`: 250, `Block Size`: 128 | 0.9059            | 144 Minutes      | Achieved strong performance for binary classification but struggled with multi-class delays. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a09fd6c-0e24-45c6-a86e-38c96f36c621",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Results And Discussion\n",
    "\n",
    "## Summary of Experiments\n",
    "\n",
    "We conducted a series of experiments using four models: a Dummy Classifier as a baseline, ElasticNet Logistic Regression, Gradient-Boosted Trees, and a Multilayer Perceptron. Each model was evaluated on a temporally split dataset to ensure no temporal data leakage and to implement realistic performance metrics. Below is a detailed analysis of the results; highlighting strengths, weaknesses, and areas for improvement.\n",
    "\n",
    "### 1. Baseline Classifier\n",
    "The dummy classifier, which always predicts \"No Delay,\" set the baseline for comparison. It achieved a Weighted Recall of 0.8073, which is deceptively high due to the class imbalance in the dataset where the majority of flights experience no delays. However, its Weighted Precision and F1-Score (0.6517 and 0.7212, respectively) highlight the limitations of this simplistic approach, particularly in handling delay predictions.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. ElasticNet Logistic Regression\n",
    "The ElasticNet Logistic Regression model provided a modest improvement over the baseline, achieving a Weighted F1-Score of 0.7259. The Weighted Recall (0.8060), however, was comparable to the dummy classifier, but the addition of regularization helped improve Weighted Precision, demonstrating a better trade-off between false positives and false negatives. However, its linear nature limited its ability to capture complex patterns, especially for less frequent delay classes.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Gradient-Boosted Trees (GBT)\n",
    "GBT demonstrated the strongest performance for the \"30-45 minutes\" delay categories, benefiting from its ability to model non-linear relationships. However, its Weighted Recall (0.6800) was lower than both the baseline and ElasticNet Logistic Regression, primarily due to underperformance on minority classes like \"Small Delays,\" \"Significant Delays,\" and \"Cancellations.\" This result is partly attributed to training on only 10% of the data due to memory constraints, which exacerbated the class imbalance issue.\n",
    "\n",
    "Key insights include:\n",
    "- The model showed potential to handle delays with distinct patterns, such as \"30-45 minutes.\"\n",
    "- It was hampered by resource constraints, limiting its ability to generalize.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Multilayer Perceptron (MLP)\n",
    "The MLP model achieved the highest overall metrics, with a Weighted Recall of 0.9059 and a Weighted F1-Score of 0.8650. However, a detailed analysis of the confusion matrix revealed significant limitations:\n",
    "- The model primarily acted as a **binary classifier**, predicting only \"No Delay\" (Class 0) and \"Small Delays\" (Class 1).\n",
    "- It failed entirely to predict moderate delays (Class 2), significant delays (Class 3), and cancellations (Class 4), resulting in F1-Scores of 0.0000 for these classes.\n",
    "\n",
    "Despite its strong performance for the dominant classes, the MLP struggled with multi-class classification, underscoring the need for strategies to address class imbalance and improve generalization across all delay categories.\n",
    "\n",
    "---\n",
    "\n",
    "## Performance Comparison Table\n",
    "\n",
    "| Metric                   | Dummy Classifier | ElasticNet Logistic Regression | Gradient-Boosted Trees | MLP   |\n",
    "|--------------------------|------------------|--------------------------------|-------------------------|-------|\n",
    "| **Weighted Precision**   | 0.6517           | 0.6788                         | 0.6500                  | 0.8435|\n",
    "| **Weighted Recall**      | 0.8073           | 0.8060                         | 0.6800                  | 0.9059|\n",
    "| **Weighted F1-Score**    | 0.7212           | 0.7259                         | 0.6900                  | 0.8650|\n",
    "\n",
    "---\n",
    "\n",
    "## Key Observations\n",
    "1. **Baseline Classifier**: The high recall of the dummy classifier highlights the dataset's imbalance, as it achieves reasonable performance by always predicting the majority class.\n",
    "2. **ElasticNet Logistic Regression**: While robust for initial testing, the linear approach struggled to capture the complex relationships necessary for multi-class delay prediction.\n",
    "3. **Gradient-Boosted Trees**: GBT seemed to perform best in capturing non-linear relationships, particularly for \"No Delay\" and \"30-45 minutes\" delay categories, but suffered due to insufficient training data and class imbalance.\n",
    "4. **Multilayer Perceptron**: The MLP achieved the highest overall metrics but failed to effectively address the multi-class nature of the problem, acting more like a binary classifier.\n",
    "\n",
    "---\n",
    "\n",
    "## Gap Analysis\n",
    "\n",
    "### Key Issues Identified:\n",
    "1. **Class Imbalance**: All models struggled with the highly imbalanced nature of the dataset, leading to poor performance on minority classes.\n",
    "2. **Underutilization of Features**: While the feature engineering process introduced valuable predictors, the limited dataset used for GBT training restricted the ability to fully leverage the predictive power of these features.\n",
    "3. **Model Behavior**: The MLP’s binary-like classification behavior underscores the need for more advanced techniques to address multi-class imbalances.\n",
    "\n",
    "### Recommendations for Improvement\n",
    "1. **Oversampling/Undersampling**:\n",
    "   - Use techniques such as SMOTE (Synthetic Minority Oversampling) to improve representation of minority classes during training.\n",
    "   - Investigate undersampling dominant classes to balance the dataset.\n",
    "\n",
    "2. **Alternative Architectures**:\n",
    "   - Experiment with ensemble methods (e.g., Random Forests or hybrid models combining GBT and MLP) to better capture multi-class distinctions.\n",
    "   - Use attention-based architectures to focus on minority class patterns.\n",
    "\n",
    "3. **Enhanced Feature Engineering**:\n",
    "   - Revisit temporal features to identify trends or anomalies specific to delayed flights.\n",
    "   - Re-calculate features to ensure leakage integrity. \n",
    "\n",
    "4. **Improved Training Strategies**:\n",
    "   - Apply class-weighting or cost-sensitive learning to prioritize accurate predictions for minority classes.\n",
    "   - Train GBT on the full dataset to improve generalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37780ac3-949b-4cfa-bfd3-d9145896e190",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Conclusion \n",
    "\n",
    "This project focused on predicting flight delay severity using the OTPW dataset, an integration of flight performance and weather data. Predicting delays is critical for optimizing resource allocation improving traveler experience, and aiding airline decision-making. Our hypothesis was that a custom ML pipeline with engineered features could accurately classify flight delays into five severity categories, leveraging advanced models to capture complax patterns.\n",
    "\n",
    "We explored various models, incuding ElasticNet Logistic Regression, Gradient Boosted Trees, and a Multilayer Peerceptron (MLP) neural network. The MLP demonstrated the best overall performance, achieving a weighted F1-score of 0.8650. This was driven by features like departure time blocks, weather conditions, and carrier-based seasonality patterns. Hyperparameter tuning across all models further enhanced their predicitve capability, with the best configuration for MLP being a two-hidden-layer architecture using ReLU activation, early stopping, and a learning rate scheduler.\n",
    "\n",
    "The results highlight the significance of sophisticated modeling and feature engineering in addressing complex, imbalanced datasets. While the MLP performed well for dominant classes, the challenges of predicting minority classes and handling class imbalance underscore areas for future work. Oversampling methods like SMOTE, improved regularization, and ensemble approaches may help balance predictions across all delay categories. Additionally, further refinement of temporal features and advanced architectures could enhance generalization and interpretability.\n",
    "\n",
    "In summary, this project established a scalable, distributed ML pipeline and demonstrated the effectiveness of custom featues and advanced models in prediciting flight delays. Future iterations can build on these findings to achieve greater accuracy and class balance ensuring broader applicabality and impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b1f08f3-e0df-4244-9e4a-fe9a97611af2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Extra Credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21fe05c9-0363-430b-8317-0d36ebc75985",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## CPU based MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a92212fb-a2aa-4ec9-ac47-f5dede5cd44a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To address the requirements of the project, a custom Multilayer Perceptron (MLP) neural network was implemented using a fully distributed approach on a CPU cluster. This implementation avoids relying on PySpark ML libraries, adhering to the extra credit guidelines. The architecture of the network includes flexibility for experimenting with one or two hidden layers, utilizing ReLU activation functions for non-linearity and softmax for output layer classification.\n",
    "\n",
    "The training process uses a synchronous gradient descent approach, where gradients are calculated for mini-batches across distributed partitions using Spark RDDs. For optimization, initialization was applied to weight matrices to improve convergence by normalizing the variance of inputs and outputs. The forward and backward passes compute the activations and gradients layer by layer, with support for a secondary hidden layer. Early stopping was incorporated to halt training upon stagnation of validation accuracy, with a patience threshold of three epochs. A custom learning rate scheduler reduces the learning rate as training progresses, helping the model converge to a local optimum.\n",
    "\n",
    "For testing purposes, the MLP was evaluated on the 3-month (3m) dataset, ensuring a smaller-scale validation of the distributed training pipeline and balanced dataset strategies.\n",
    "\n",
    "---\n",
    "\n",
    "### Results\n",
    "\n",
    "The MLP model was trained and evaluated on the balanced training data generated through oversampling to mitigate class imbalance. The results on the 3m test dataset are as follows:\n",
    "\n",
    "- **Test Accuracy**: 57.25%\n",
    "- **Confusion Matrix**:\n",
    "\n",
    "  | True Label | Predicted: Class 0 | Predicted: Class 1 | Predicted: Class 2 | Predicted: Class 3 | Predicted: Class 4 |\n",
    "  |------------|---------------------|---------------------|---------------------|---------------------|---------------------|\n",
    "  | **Class 0** | 157200              | 3354                | 73171               | 7741                | 8                   |\n",
    "  | **Class 1** | 0                   | 0                   | 71                  | 31554               | 0                   |\n",
    "  | **Class 2** | 0                   | 0                   | 0                   | 9613                | 0                   |\n",
    "  | **Class 3** | 0                   | 0                   | 0                   | 10747               | 0                   |\n",
    "  | **Class 4** | 0                   | 0                   | 0                   | 0                   | 107                 |\n",
    "\n",
    "---\n",
    "\n",
    "The test accuracy of 57.25% is a moderate classification performance, with the model heavily favoring Class 0 in predictions. The confusion matrix highlights the imbalance in predictive capability, as the majority of misclassifications occur for Class 1 and Class 2, which are primarily misclassified as Class 3.\n",
    "\n",
    "### Discussion\n",
    "\n",
    "While the architecture of the implemented MLP is designed for scalability, the results indicate limitations in capturing the intricacies of the dataset. The model's tendency to bias predictions toward certain classes, despite oversampling, suggests that further refinements are necessary. Possible improvements include experimenting with deeper architectures, adjusting the learning rate decay, or introducing regularization techniques such as dropout to prevent overfitting on oversampled data. Additionally, exploring ensemble methods or Gradient Boosted Decision Trees alongside the MLP could yield complementary insights and better classification performance.\n",
    "\n",
    "Overall, the implementation successfully fulfills the extra credit requirements by employing a fully distributed, scalable CPU-based neural network. The use of the 3m dataset for testing purposes provided a meaningful evaluation of the methodology and highlighted areas for future improvement in achieving better generalization and balance in predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c07d3b1-9f62-4a91-9617-07c2f4b5d21c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Phase 3 Outline",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}